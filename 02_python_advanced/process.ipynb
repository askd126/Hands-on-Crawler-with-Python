{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T10:44:01.413021100Z",
     "start_time": "2023-11-27T10:44:01.353672100Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "'''\n",
    "@Author   :   Corley Tang\n",
    "@contact  :   cutercorleytd@gmail.com\n",
    "@Github   :   https://github.com/corleytd\n",
    "@Time     :   2023-11-27 23:18\n",
    "@Project  :   Hands-on Crawler with Python-process\n",
    "进程\n",
    "'''\n",
    "\n",
    "# 导入所需的库\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "from multiprocessing import Process, Pool, Lock, RLock, Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b945aa7ce0ba161",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1.multiprocessing库\n",
    "Python中的多进程是通过multiprocessing库来实现的，和多线程的threading.Thread差不多，它可以利用multiprocessing.Process类来创建一个进程对象，其使用方法与threading库很像。\n",
    "\n",
    "Python进程在不同的系统启动方式不同：\n",
    "- spawn：父进程会启动一个全新的Python解释器进程，子进程会继承那些运行进程对象的run()方法所必需的资源。使用此方法启动进程相比使用fork或forkserver要慢上许多，在Unix、Windows、MacOS上使用，同时是Windows的默认设置。\n",
    "- fork：父进程和子进程共享内存，但互不影响，子进程会继承父进程的运行状态。使用此方法启动进程相比使用spawn要快很多，在Unix上使用。\n",
    "- forkserver：程序选择forkserver启动方法时，每当需要一个新进程时，父进程就会连接到服务器并请求它分叉一个新进程，分叉服务器进程是单线程的，因此使用os.fork()是安全的，没有不必要的资源被继承。可在Unix平台上使用，支持通过Unix管道传递文件描述符。\n",
    "\n",
    "Windows默认使用spawn方式创建新进程，而Unix（Linux）使用fork方式创建新进程。同时，因为Windows没有fork机制，只能使用spawn方式，而该方法会先创建出一个子进程，为了获得相同的功能，子进程会再次运行代码，此时代码中需要有__main__来区分父进程和子进程。下面的示例都是基于Linux来实现的，如果想要在Windows实现，应该使用Python脚本文件而不是Jupyter Notebook等交互式环境，同时应该将主线程用`if __name__ == '__main__':`进行包裹。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b11c45a8a108bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T09:04:22.847031800Z",
     "start_time": "2023-11-22T09:04:22.282662100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process-3 worker finished in 0.5238 seconds\n",
      "process-4 worker finished in 0.8303 seconds\n",
      "process-2 worker finished in 1.2532 seconds\n",
      "process-1 worker finished in 3.4665 seconds\n",
      "process-0 worker finished in 4.2249 seconds\n",
      "Main Done\n"
     ]
    }
   ],
   "source": [
    "# 方式1：直接实例化Process类\n",
    "def sleep_for_seconds(name):\n",
    "    work_time = random.random() * 5\n",
    "    time.sleep(work_time)\n",
    "    print(f'{name} worker finished in {work_time:.4f} seconds')\n",
    "\n",
    "\n",
    "tasks = []\n",
    "for i in range(5):\n",
    "    p = Process(target=sleep_for_seconds, args=(f'process-{i}',))\n",
    "    p.start()\n",
    "    tasks.append(p)\n",
    "\n",
    "for task in tasks:\n",
    "    task.join()\n",
    "\n",
    "print('Main Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "369b942c4cbe9814",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T09:04:24.130641300Z",
     "start_time": "2023-11-22T09:04:22.851025300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process-0 worker finished in 0.8161 seconds\n",
      "process-1 worker finished in 0.5090 seconds\n",
      "process-2 worker finished in 2.2470 seconds\n",
      "process-3 worker finished in 0.4468 seconds\n",
      "process-4 worker finished in 1.6233 seconds\n",
      "Main Done\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    p = Process(target=sleep_for_seconds, args=(f'process-{i}',))\n",
    "    p.start()\n",
    "    p.join()  # 每一个进程在start之后调用join\n",
    "\n",
    "print('Main Done')  # 速度变慢，由并行变为串行，因为join()方法将阻塞直到调用该方法的进程终止。一个进程可以被join多次；进程无法join自身，因为这会导致死锁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6a7a2268a7f756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T09:04:24.620741100Z",
     "start_time": "2023-11-22T09:04:24.135139900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process-0 worker finished in 0.5188 seconds\n",
      "process-1 worker finished in 1.9588 seconds\n",
      "process-4 worker finished in 2.4376 seconds\n",
      "process-3 worker finished in 3.0578 seconds\n",
      "process-2 worker finished in 3.3478 seconds\n",
      "Main Done\n"
     ]
    }
   ],
   "source": [
    "# 方式2：继承Process类，重写run()方法\n",
    "class CustomProcess(Process):\n",
    "    def __init__(self, func, name):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.name = name\n",
    "\n",
    "    def run(self):\n",
    "        self.func(self.name)\n",
    "\n",
    "\n",
    "tasks = []\n",
    "for i in range(5):\n",
    "    p = CustomProcess(sleep_for_seconds, f'process-{i}')\n",
    "    p.start()\n",
    "    tasks.append(p)\n",
    "\n",
    "for task in tasks:\n",
    "    task.join()\n",
    "\n",
    "print('Main Done')  # 效果与方式1相同"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12fb8dcb7e72acf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2.进程池"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62d2a8c5fc9da984",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-22T09:04:24.624730900Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run main 2114\n",
      "Run task process-0 2207Run task process-1 2208Run task process-2 2209\n",
      "\n",
      "\n",
      "process-1 worker finished in 0.2262 seconds\n",
      "Run task process-3 2208\n",
      "process-0 worker finished in 2.2371 seconds\n",
      "Run task process-4 2207\n",
      "process-2 worker finished in 3.3186 seconds\n",
      "process-3 worker finished in 3.1034 seconds\n",
      "process-4 worker finished in 3.0111 seconds\n",
      "Main Done\n"
     ]
    }
   ],
   "source": [
    "def sleep_for_seconds(name):\n",
    "    print(f'Run task {name} {os.getpid()}')\n",
    "    work_time = random.random() * 5\n",
    "    time.sleep(work_time)\n",
    "    print(f'{name} worker finished in {work_time:.4f} seconds')\n",
    "\n",
    "\n",
    "print(f'Run main {os.getpid()}')\n",
    "pool = Pool(3)\n",
    "for i in range(5):\n",
    "    pool.apply_async(sleep_for_seconds, args=(f'process-{i}',))\n",
    "pool.close()  # join钱必须调用close()，调用close()之后不能继续添加新的进程\n",
    "pool.join()  # 调用join()方法会等待所有子进程执行完毕\n",
    "print('Main Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7872805bffb7a1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3.进程锁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "828957d89b53c63e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T09:13:59.713878400Z",
     "start_time": "2023-11-22T09:13:59.537838200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2255 is running\n",
      "0: 2255 is done\n",
      "1: 2256 is running\n",
      "1: 2256 is done\n",
      "2: 2261 is running\n",
      "2: 2261 is done\n",
      "3: 2262 is running\n",
      "3: 2262 is done\n",
      "4: 2263 is running\n",
      "4: 2263 is done\n",
      "5: 2264 is running\n",
      "5: 2264 is done\n",
      "6: 2265 is running\n",
      "6: 2265 is done\n",
      "7: 2266 is running\n",
      "7: 2266 is done\n",
      "8: 2267 is running\n",
      "8: 2267 is done\n",
      "9: 2268 is running\n",
      "9: 2268 is done\n"
     ]
    }
   ],
   "source": [
    "def sleep_for_seconds(i, lock):\n",
    "    try:\n",
    "        lock.acquire()  # 获取锁：控制一段代码在同一时间只能被一个进程执行，如果在locked得锁上再次获取，会阻塞进程\n",
    "        print(f'{i}: {os.getpid()} is running')\n",
    "        time.sleep(random.random() * 5)\n",
    "        print(f'{i}: {os.getpid()} is done')\n",
    "    finally:\n",
    "        lock.release()  # 释放锁\n",
    "\n",
    "\n",
    "lock = Lock()\n",
    "for i in range(10):\n",
    "    Process(target=sleep_for_seconds, args=(i, lock)).start()  # 使用锁保证进程启动顺序和结束顺序一致，一个进程运行结束才开始运行下一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a92174b7120c01f5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2269 is running\n",
      "0: 2269 is done\n",
      "1: 2270 is running\n",
      "1: 2270 is done\n",
      "2: 2275 is running\n",
      "2: 2275 is done\n",
      "3: 2276 is running\n",
      "3: 2276 is done\n",
      "4: 2277 is running\n",
      "4: 2277 is done\n",
      "5: 2278 is running\n",
      "5: 2278 is done\n",
      "6: 2279 is running\n",
      "6: 2279 is done\n",
      "7: 2280 is running\n",
      "7: 2280 is done\n",
      "8: 2281 is running\n",
      "8: 2281 is done\n",
      "9: 2282 is running\n",
      "9: 2282 is done\n"
     ]
    }
   ],
   "source": [
    "# 使用with语句替代\n",
    "def sleep_for_seconds(i, lock):\n",
    "    with lock:\n",
    "        print(f'{i}: {os.getpid()} is running')\n",
    "        time.sleep(random.random() * 5)\n",
    "        print(f'{i}: {os.getpid()} is done')\n",
    "\n",
    "\n",
    "lock = Lock()\n",
    "for i in range(10):\n",
    "    Process(target=sleep_for_seconds, args=(i, lock)).start()  # 效果相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dbd7c970feaf00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T09:20:27.282424300Z",
     "start_time": "2023-11-22T09:20:26.983022500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2283 is running\n",
      "0: 2283 is done\n",
      "1: 2284 is running\n",
      "1: 2284 is done\n",
      "2: 2287 is running\n",
      "2: 2287 is done\n",
      "3: 2288 is running\n",
      "3: 2288 is done\n",
      "4: 2291 is running\n",
      "4: 2291 is done\n",
      "5: 2292 is running\n",
      "5: 2292 is done\n",
      "6: 2293 is running\n",
      "6: 2293 is done\n",
      "7: 2294 is running\n",
      "7: 2294 is done\n",
      "8: 2295 is running\n",
      "8: 2295 is done\n",
      "9: 2296 is running\n",
      "9: 2296 is done\n"
     ]
    }
   ],
   "source": [
    "# 可重入锁\n",
    "def sleep_for_seconds(i, lock):\n",
    "    try:\n",
    "        lock.acquire()  # 获取锁\n",
    "        lock.acquire()  # 再次获取锁\n",
    "        print(f'{i}: {os.getpid()} is running')\n",
    "        time.sleep(random.random() * 5)\n",
    "        print(f'{i}: {os.getpid()} is done')\n",
    "    finally:\n",
    "        lock.release()  # 释放锁\n",
    "        lock.release()  # 再次释放锁\n",
    "\n",
    "\n",
    "lock = RLock()\n",
    "for i in range(10):\n",
    "    Process(target=sleep_for_seconds, args=(i, lock)).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d083dc975cb1e6c3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 4.进程通信"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4910585756b8d5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T10:53:19.527142500Z",
     "start_time": "2023-11-23T10:53:17.241036Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 2297 is writing...\n",
      "Put ChatGPT into queue...\n",
      "Process 2298 is reading...\n",
      "Get ChatGPT from queue...\n",
      "Put ERNIE Bot into queue...\n",
      "Get ERNIE Bot from queue...\n",
      "Put QianWen into queue...\n",
      "Get QianWen from queue...\n",
      "Put iFLYTEK Spark into queue...\n",
      "Get iFLYTEK Spark from queue...\n",
      "Put ChatGLM into queue...\n",
      "Get ChatGLM from queue...\n"
     ]
    }
   ],
   "source": [
    "# Queue实现进程间通信\n",
    "chat_names = ['ChatGPT', 'ERNIE Bot', 'QianWen', 'iFLYTEK Spark', 'ChatGLM']\n",
    "\n",
    "\n",
    "# 进程写数据\n",
    "def write(q):\n",
    "    print(f'Process {os.getpid()} is writing...')\n",
    "    for value in chat_names:\n",
    "        print(f'Put {value} into queue...')\n",
    "        q.put(value)\n",
    "        time.sleep(random.random() * 5)\n",
    "\n",
    "\n",
    "# 进程读数据\n",
    "def read(q):\n",
    "    print(f'Process {os.getpid()} is reading...')\n",
    "    while True:\n",
    "        value = q.get()\n",
    "        print(f'Get {value} from queue...')\n",
    "\n",
    "\n",
    "# 父进程创建队列，并传给2个子进程\n",
    "q = Queue()\n",
    "pw = Process(target=write, args=(q,))\n",
    "pr = Process(target=read, args=(q,))\n",
    "pw.start()  # 启动写进程\n",
    "pr.start()  # 启动读进程\n",
    "pw.join()  # 等待写进程结束\n",
    "pr.kill()  # 强行终止进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d77276ffe3542882",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T10:59:45.662907600Z",
     "start_time": "2023-11-23T10:59:45.087810100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 2479 is writing...\n",
      "Put CustomClass(ChatGPT) into queue...Process 2480 is reading...\n",
      "\n",
      "Get CustomClass(ChatGPT) from queue...\n",
      "Put CustomClass(ERNIE Bot) into queue...\n",
      "Get CustomClass(ERNIE Bot) from queue...\n",
      "Put CustomClass(QianWen) into queue...\n",
      "Get CustomClass(QianWen) from queue...\n",
      "Put CustomClass(iFLYTEK Spark) into queue...\n",
      "Get CustomClass(iFLYTEK Spark) from queue...\n",
      "Put CustomClass(ChatGLM) into queue...\n",
      "Get CustomClass(ChatGLM) from queue...\n"
     ]
    }
   ],
   "source": [
    "# 通信内容为自定义类实例\n",
    "class CustomClass:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'CustomClass({self.name})'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'CustomClass({self.name})'\n",
    "\n",
    "\n",
    "def write(q):\n",
    "    print(f'Process {os.getpid()} is writing...')\n",
    "    for value in [CustomClass(name) for name in chat_names]:\n",
    "        print(f'Put {value} into queue...')\n",
    "        q.put(value)\n",
    "        time.sleep(random.random() * 5)\n",
    "\n",
    "\n",
    "def read(q):\n",
    "    print(f'Process {os.getpid()} is reading...')\n",
    "    while True:\n",
    "        value = q.get()\n",
    "        print(f'Get {value} from queue...')\n",
    "\n",
    "\n",
    "q = Queue()\n",
    "pw = Process(target=write, args=(q,))\n",
    "pr = Process(target=read, args=(q,))\n",
    "pw.start()\n",
    "pr.start()\n",
    "pw.join()\n",
    "pr.kill()  # 正常运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12bc5aaa9018970f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T11:02:11.148064700Z",
     "start_time": "2023-11-23T11:02:10.844702100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 2607 is writing...\n",
      "Put CustomClass(ChatGPT) into queue...Process 2608 is reading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/synchronize.py\", line 101, in __getstate__\n",
      "    context.assert_spawning(self)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/context.py\", line 359, in assert_spawning\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Lock objects should only be shared between processes through inheritance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put CustomClass(ERNIE Bot) into queue...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/synchronize.py\", line 101, in __getstate__\n",
      "    context.assert_spawning(self)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/context.py\", line 359, in assert_spawning\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Lock objects should only be shared between processes through inheritance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put CustomClass(QianWen) into queue...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/synchronize.py\", line 101, in __getstate__\n",
      "    context.assert_spawning(self)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/context.py\", line 359, in assert_spawning\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Lock objects should only be shared between processes through inheritance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put CustomClass(iFLYTEK Spark) into queue...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/synchronize.py\", line 101, in __getstate__\n",
      "    context.assert_spawning(self)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/context.py\", line 359, in assert_spawning\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Lock objects should only be shared between processes through inheritance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put CustomClass(ChatGLM) into queue...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/synchronize.py\", line 101, in __getstate__\n",
      "    context.assert_spawning(self)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/context.py\", line 359, in assert_spawning\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Lock objects should only be shared between processes through inheritance\n"
     ]
    }
   ],
   "source": [
    "# 通信内容为自定义类实例，同时在类中使用锁：不支持，因为锁对象只能通过传参在进程之间共享，不能通过进程通信的形式传输\n",
    "class CustomClass:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.lock = Lock()\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'CustomClass({self.name})'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'CustomClass({self.name})'\n",
    "\n",
    "\n",
    "def write(q):\n",
    "    print(f'Process {os.getpid()} is writing...')\n",
    "    for value in [CustomClass(name) for name in chat_names]:\n",
    "        print(f'Put {value} into queue...')\n",
    "        q.put(value)\n",
    "        time.sleep(random.random() * 5)\n",
    "\n",
    "\n",
    "def read(q):\n",
    "    print(f'Process {os.getpid()} is reading...')\n",
    "    while True:\n",
    "        value = q.get()\n",
    "        print(f'Get {value} from queue...')\n",
    "\n",
    "\n",
    "q = Queue()\n",
    "pw = Process(target=write, args=(q,))\n",
    "pr = Process(target=read, args=(q,))\n",
    "pw.start()\n",
    "pr.start()\n",
    "pw.join()\n",
    "pr.kill()  # 报错：RuntimeError: Lock objects should only be shared between processes through inheritance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c61143200f4fba8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 2726 is writing...\n",
      "Put CustomClass(ChatGPT) into queue...\n",
      "Process 2727 is reading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "AttributeError: Can't pickle local object 'CustomClass.__init__.<locals>.<lambda>'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put CustomClass(ERNIE Bot) into queue...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "AttributeError: Can't pickle local object 'CustomClass.__init__.<locals>.<lambda>'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put CustomClass(QianWen) into queue...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "AttributeError: Can't pickle local object 'CustomClass.__init__.<locals>.<lambda>'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put CustomClass(iFLYTEK Spark) into queue...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "AttributeError: Can't pickle local object 'CustomClass.__init__.<locals>.<lambda>'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put CustomClass(ChatGLM) into queue...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "AttributeError: Can't pickle local object 'CustomClass.__init__.<locals>.<lambda>'\n"
     ]
    }
   ],
   "source": [
    "# 通信内容为自定义类实例，同时在类中使用lambda匿名函数：不支持，因为Queue的实现原理是，当一个对象要被放入队列中时，这个对象首先会被一个后台线程用pickle 序列化，并将序列化后的数据通过一个底层管道的管道传递到队列中，而lambda不支持被序列化\n",
    "class CustomClass:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.func = lambda x: len(x)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'CustomClass({self.name})'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'CustomClass({self.name})'\n",
    "\n",
    "\n",
    "def write(q):\n",
    "    print(f'Process {os.getpid()} is writing...')\n",
    "    for value in [CustomClass(name) for name in chat_names]:\n",
    "        print(f'Put {value} into queue...')\n",
    "        q.put(value)\n",
    "        time.sleep(random.random() * 5)\n",
    "\n",
    "\n",
    "def read(q):\n",
    "    print(f'Process {os.getpid()} is reading...')\n",
    "    while True:\n",
    "        value = q.get()\n",
    "        print(f'Get {value} from queue...')\n",
    "\n",
    "\n",
    "q = Queue()\n",
    "pw = Process(target=write, args=(q,))\n",
    "pr = Process(target=read, args=(q,))\n",
    "pw.start()\n",
    "pr.start()\n",
    "pw.join()\n",
    "pr.kill()  # 报错：AttributeError: Can't pickle local object 'CustomClass.__init__.<locals>.<lambda>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d365913501ffc36",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 5.进程池ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cee36fbcddb7c15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T10:43:22.468850100Z",
     "start_time": "2023-11-27T10:43:20.127230600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "45\n",
      "4950\n",
      "499500\n",
      "49995000\n",
      "4999950000\n",
      "499999500000\n",
      "49999995000000\n",
      "4999999950000000\n",
      "499999999500000000\n"
     ]
    }
   ],
   "source": [
    "# 使用进程池\n",
    "def sum_numbers(n):\n",
    "    res = 0\n",
    "    for i in range(n):\n",
    "        res += i\n",
    "    return res\n",
    "\n",
    "\n",
    "nums = [1, 10, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000]\n",
    "with ProcessPoolExecutor(max_workers=3) as executor:  # 进程池\n",
    "    tasks = [executor.submit(sum_numbers, num) for num in nums]\n",
    "    for task in as_completed(tasks):\n",
    "        print(task.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b98eaf803da5140b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "45\n",
      "4950\n",
      "499500\n",
      "49995000\n",
      "4999950000\n",
      "499999500000\n",
      "49999995000000\n",
      "4999999950000000\n",
      "499999999500000000\n",
      "Sequential execution in 87.8482 seconds\n",
      "499500\n",
      "49995000\n",
      "45\n",
      "4950\n",
      "0\n",
      "4999950000\n",
      "499999500000\n",
      "49999995000000\n",
      "4999999950000000\n",
      "499999999500000000\n",
      "Thread pool execution in 105.0270 seconds\n",
      "0\n",
      "4950\n",
      "499500\n",
      "45\n",
      "49995000\n",
      "4999950000\n",
      "499999500000\n",
      "49999995000000\n",
      "4999999950000000\n",
      "499999999500000000\n",
      "Process pool execution in 81.6088 seconds\n"
     ]
    }
   ],
   "source": [
    "# 进程池与线程池的比较\n",
    "# 顺序执行\n",
    "start = time.perf_counter()\n",
    "for num in nums:\n",
    "    res = sum_numbers(num)\n",
    "    print(res)\n",
    "print(f'Sequential execution in {time.perf_counter() - start:.4f} seconds')\n",
    "\n",
    "# 线程池执行\n",
    "start = time.perf_counter()\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    tasks = [executor.submit(sum_numbers, num) for num in nums]\n",
    "    for task in as_completed(tasks):\n",
    "        print(task.result())\n",
    "print(f'Thread pool execution in {time.perf_counter() - start:.4f} seconds')\n",
    "\n",
    "# 进程池执行\n",
    "start = time.perf_counter()\n",
    "with ProcessPoolExecutor(max_workers=3) as executor:\n",
    "    tasks = [executor.submit(sum_numbers, num) for num in nums]\n",
    "    for task in as_completed(tasks):\n",
    "        print(task.result())\n",
    "print(\n",
    "    f'Process pool execution in {time.perf_counter() - start:.4f} seconds')  # 相比于线程池，ProcessPoolExecutor使用了多核处理的模块，使得可以不受GIL的限制，大大缩短执行时间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f3d81f176bb62b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "线程和进程是操作系统中的两个基本概念，它们在Python中也有所体现。\n",
    "\n",
    "关系：\n",
    "- 一个进程可以包含多个线程，这些线程共享进程的资源，如内存、文件等。\n",
    "- 线程相对于进程来说，创建、销毁和切换的开销更小，因此多线程可以提高程序的执行效率。\n",
    "- 线程之间可以通过同步机制（如锁、信号量等）进行通信和协作。\n",
    "\n",
    "区别：\n",
    "- 资源分配：进程是资源分配的基本单位，每个进程拥有独立的内存空间和系统资源；而线程是CPU调度的基本单位，多个线程共享同一个进程的资源。\n",
    "- 独立性：进程之间是独立的，一个进程崩溃不会影响到其他进程；而线程之间是共享资源的，一个线程崩溃可能会导致整个进程崩溃。\n",
    "- 通信方式：进程间通信需要借助IPC（进程间通信）机制，如管道、消息队列等；而线程间通信相对简单，可以直接访问共享变量、全局变量等。\n",
    "- 数据传递：由于进程之间的内存空间是独立的，因此进程间的数据传递需要通过IPC机制；而线程共享同一进程的内存空间，数据传递相对简单。\n",
    "- 内存管理：每个进程拥有独立的内存空间，需要单独进行内存分配和回收；而线程共享同一进程的内存空间，内存管理相对简单。\n",
    "- 上下文切换：进程间的上下文切换开销较大，因为涉及到内存、CPU等资源的分配和回收；而线程间的上下文切换开销较小，因为它们共享同一进程的资源。\n",
    "- 编程模型：多进程编程需要考虑进程间的同步和互斥问题，通常使用multiprocessing模块；而多线程编程需要考虑线程间的同步和互斥问题，通常使用threading模块。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
